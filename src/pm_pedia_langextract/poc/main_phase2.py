"""Phase 2 execution script for project integration."""

import json
from pathlib import Path
from datetime import datetime
from typing import List, Dict, Any

from dotenv import load_dotenv

from pm_pedia_langextract.poc.extractors import IntegrationExtractor
from pm_pedia_langextract.utils.logging_config import setup_logging, get_logger

# ç’°å¢ƒè¨­å®š
load_dotenv()
setup_logging(level="INFO")
logger = get_logger(__name__)


def run_phase2() -> Dict[str, Any]:
    """ãƒ•ã‚§ãƒ¼ã‚º2: çµ±åˆãƒ»æ§‹é€ åŒ–å‡¦ç†."""
    logger.info("=== PM-pedia PoC Phase 2 é–‹å§‹ ===")
    
    # ãƒ•ã‚§ãƒ¼ã‚º1ã®å‡ºåŠ›ãƒ•ã‚¡ã‚¤ãƒ«ã‚’å–å¾—
    phase1_output_dir = Path("data/output/phase1")
    snippet_files = list(phase1_output_dir.glob("*_snippets.jsonl"))
    
    if not snippet_files:
        raise FileNotFoundError(
            "Phase 1ã®å‡ºåŠ›ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚å…ˆã«Phase 1ã‚’å®Ÿè¡Œã—ã¦ãã ã•ã„ã€‚\n"
            f"æœŸå¾…ã™ã‚‹ãƒ‘ã‚¹: {phase1_output_dir}/*_snippets.jsonl"
        )
    
    logger.info(f"çµ±åˆå¯¾è±¡ãƒ•ã‚¡ã‚¤ãƒ«: {len(snippet_files)}ä»¶")
    for f in snippet_files:
        logger.info(f"  - {f.name}")
    
    # çµ±åˆå‡¦ç†å®Ÿè¡Œ
    logger.info("çµ±åˆæŠ½å‡ºå™¨ã‚’åˆæœŸåŒ–ä¸­...")
    integrator = IntegrationExtractor()
    
    logger.info("çµ±åˆå‡¦ç†ã‚’å®Ÿè¡Œä¸­...")
    result = integrator.extract(snippet_files)
    
    # çµæœã‚’ä¿å­˜
    output_dir = Path("data/output/phase2")
    output_dir.mkdir(parents=True, exist_ok=True)
    
    output_path = output_dir / "unified_projects.json"
    
    with open(output_path, 'w', encoding='utf-8') as f:
        json.dump(result, f, ensure_ascii=False, indent=2)
    
    logger.info(f"\n=== Phase 2 å®Œäº† ===")
    logger.info(f"çµ±åˆçµæœ: {output_path}")
    logger.info(f"çµ±åˆã•ã‚ŒãŸãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆæ•°: {len(result['unified_projects'])}")
    
    # çµæœã®è©³ç´°è¡¨ç¤º
    logger.info("\n--- çµ±åˆã•ã‚ŒãŸãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆè©³ç´° ---")
    for i, project in enumerate(result['unified_projects'], 1):
        logger.info(f"\n{i}. {project['project_name']} (ID: {project['project_id']})")
        logger.info(f"   ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹: {project['status']}")
        
        if project['aliases']:
            logger.info(f"   åˆ¥å: {', '.join(project['aliases'])}")
        
        if project['key_themes']:
            logger.info(f"   ä¸»è¦ãƒ†ãƒ¼ãƒ: {', '.join(project['key_themes'])}")
            
        if project['mentioned_people']:
            logger.info(f"   é–¢ä¿‚è€…: {', '.join(project['mentioned_people'])}")
        
        logger.info(f"   é–¢é€£ã‚¹ãƒ‹ãƒšãƒƒãƒˆ: {len(project['information_snippets'])}ä»¶")
        
        # ã‚µãƒãƒªãƒ¼ã‚’é©åˆ‡ãªé•·ã•ã§è¡¨ç¤º
        summary = project['summary']
        if len(summary) > 150:
            summary = summary[:147] + "..."
        logger.info(f"   è¦ç´„: {summary}")
    
    # æŠ½å‡ºãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿è¡¨ç¤º
    metadata = result['extraction_metadata']
    logger.info(f"\n--- å‡¦ç†çµ±è¨ˆ ---")
    logger.info(f"å‡¦ç†ãƒ•ã‚¡ã‚¤ãƒ«æ•°: {metadata['processed_files']}")
    logger.info(f"ä½¿ç”¨ãƒ¢ãƒ‡ãƒ«: {metadata['model_used']}")
    logger.info(f"å‡¦ç†æ™‚åˆ»: {metadata['timestamp']}")
    
    return result


def analyze_results(result: Dict[str, Any]) -> None:
    """çµæœã‚’åˆ†æã—ã¦æ´å¯Ÿã‚’è¡¨ç¤º."""
    logger.info("\n=== çµæœåˆ†æ ===")
    
    projects = result['unified_projects']
    
    # ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹åˆ†å¸ƒ
    status_count = {}
    for project in projects:
        status = project['status']
        status_count[status] = status_count.get(status, 0) + 1
    
    logger.info("ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹åˆ†å¸ƒ:")
    for status, count in status_count.items():
        logger.info(f"  {status}: {count}ä»¶")
    
    # æœ€ã‚‚å¤šãã®äººãŒé–¢ã‚ã£ã¦ã„ã‚‹ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆ
    if projects:
        max_people_project = max(projects, key=lambda p: len(p['mentioned_people']))
        if max_people_project['mentioned_people']:
            logger.info(f"\næœ€ã‚‚å¤šãã®é–¢ä¿‚è€…ãŒé–¢ã‚ã‚‹ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆ:")
            logger.info(f"  {max_people_project['project_name']} ({len(max_people_project['mentioned_people'])}äºº)")
            logger.info(f"  é–¢ä¿‚è€…: {', '.join(max_people_project['mentioned_people'])}")
    
    # æœ€ã‚‚å¤šãã®ã‚¹ãƒ‹ãƒšãƒƒãƒˆãŒã‚ã‚‹ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆ
    if projects:
        max_snippets_project = max(projects, key=lambda p: len(p['information_snippets']))
        logger.info(f"\næœ€ã‚‚å¤šãã®æƒ…å ±ãŒã‚ã‚‹ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆ:")
        logger.info(f"  {max_snippets_project['project_name']} ({len(max_snippets_project['information_snippets'])}ä»¶)")


if __name__ == "__main__":
    try:
        result = run_phase2()
        analyze_results(result)
        
        logger.info("\nğŸ‰ PM-pedia PoC Phase 2 ãŒæ­£å¸¸ã«å®Œäº†ã—ã¾ã—ãŸï¼")
        logger.info("\nçµæœãƒ•ã‚¡ã‚¤ãƒ«:")
        logger.info("  ğŸ“Š data/output/phase2/unified_projects.json")
        logger.info("\næ¬¡ã®ã‚¹ãƒ†ãƒƒãƒ—:")
        logger.info("  1. çµæœJSONãƒ•ã‚¡ã‚¤ãƒ«ã‚’ç¢ºèª")
        logger.info("  2. ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã®åå¯„ã›ç²¾åº¦ã‚’è©•ä¾¡")
        logger.info("  3. ã‚µãƒãƒªãƒ¼ã®è³ªã‚’ç¢ºèª")
        
    except Exception as e:
        logger.error("PoC Phase 2 ã§ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ", exc_info=True)
        raise